{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cd2063",
   "metadata": {},
   "source": [
    "### Youtube Chatbot using RAG\n",
    "\n",
    "**Workflow Overview**\n",
    "\n",
    "1. **Transcript Extraction**\n",
    "  - Get transcript from YouTube video using either:\n",
    "    - LangChain YouTube loader\n",
    "    - YouTube API\n",
    "\n",
    "2. **Text Splitting**\n",
    "  - Divide transcript into manageable chunks.\n",
    "\n",
    "3. **Embedding & Vector Store**\n",
    "  - Generate embeddings for each chunk.\n",
    "  - Store embeddings in a vector database.\n",
    "\n",
    "4. **Retrieval**\n",
    "  - User sends a query.\n",
    "  - Query is embedded and a semantic search is performed in the vector store.\n",
    "\n",
    "5. **Prompt Construction**\n",
    "  - Merge retrieved chunks.\n",
    "  - Create a prompt using the retrieved context and user query.\n",
    "\n",
    "6. **LLM Response**\n",
    "  - Send the prompt to a language model (LLM).\n",
    "  - Return the generated response to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45cac7",
   "metadata": {},
   "source": [
    "#### Installation of librariees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a92575",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q youtube-transcript-api langchain-community langchain-ollama faiss-cpu tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb059d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77c987",
   "metadata": {},
   "source": [
    "#### step 1.1 : Indexing - Document ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = \"uhWzVdGmX2w\"\n",
    "try:\n",
    "    yt_api = YouTubeTranscriptApi()\n",
    "    transcript_list = yt_api.list(video_id=video_id)\n",
    "    transcript = transcript_list.find_generated_transcript(['en'])\n",
    "    print(transcript.fetch())\n",
    "except TranscriptsDisabled:\n",
    "    print(\"No captions available for this video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2fbca0",
   "metadata": {},
   "source": [
    "#### step 1.2 : Text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Extract text from snippets\n",
    "fetched = transcript.fetch()\n",
    "full_text = \" \".join([snippet.text for snippet in fetched.snippets])\n",
    "\n",
    "# Now split\n",
    "chunks = splitter.create_documents([full_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 1000 characters for quick testing\n",
    "test_text = full_text[:1000]\n",
    "test_chunks = splitter.create_documents([test_text])\n",
    "test_embeddings = OllamaEmbeddings(model=\"llama3:latest\")\n",
    "test_vector_store = FAISS.from_documents(test_chunks, test_embeddings)\n",
    "print(f\"Number of test chunks: {len(test_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d720630",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178777ee",
   "metadata": {},
   "source": [
    "#### step 1.3 & 1.4 : Embedding generaton adn storing in vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8668edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3:latest\")\n",
    "vector_store = FAISS.from_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.get_by_ids(['5c82ad3d-8155-4479-a409-e5f2c1ec5982'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8470ad",
   "metadata": {},
   "source": [
    "#### step 2 Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e333ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is deepmind\"\n",
    "retriever =vector_store.as_retriever(\n",
    "  search_type=\"similarity\",\n",
    "  search_kwargs={\"k\":4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f07910",
   "metadata": {},
   "source": [
    "#### step 3 - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3:latest\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a306339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "  template= \"\"\"\n",
    "  You are a helpful AI assistant.\n",
    "  Answer ONLY from the provided transcript context.\n",
    "  If the context is insufficient, just say \" I don't know\".\n",
    "  {context},\n",
    "  Question:{question}\n",
    "  \"\"\",\n",
    "  input_variables=[\"context\",\"question\"]\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is the topic of aliens discussed in this video ? If yes , what was discussed?\"\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04209814",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\":context_text,\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f30e3",
   "metadata": {},
   "source": [
    "#### step 4: Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c962d5",
   "metadata": {},
   "source": [
    "#### Same steps using Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "  return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "  'context': retriever | RunnableLambda(format_docs),\n",
    "  'question':RunnablePassthrough()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain.invoke(\"who is robert greene\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "main_chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ce62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain.invoke(\"summarize everything about human nature from the video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d736306",
   "metadata": {},
   "source": [
    "### Improvements for this Application\n",
    "\n",
    "1. **UI Enhancements**\n",
    "  - Streamlit-based interface\n",
    "  - Chrome extension/plugin\n",
    "\n",
    "2. **Evaluation**\n",
    "  - Ragas\n",
    "  - LangSmith\n",
    "\n",
    "3. **Indexing**\n",
    "  - Document ingestion for multiple languages\n",
    "  - Semantic text splitting\n",
    "  - Cloud-based vector store (e.g., Pinecone)\n",
    "\n",
    "4. **Retrieval**\n",
    "  - **Pre-Retrieval**\n",
    "    - Query rewriting using LLM\n",
    "    - Multi-query generation\n",
    "    - Domain-aware routing (complex RAG systems)\n",
    "  - **During Retrieval**\n",
    "    - MMR (Maximal Marginal Relevance)\n",
    "    - Hybrid retrieval\n",
    "    - Re-ranking\n",
    "  - **Post-Retrieval**\n",
    "    - Contextual compression (retain only meaningful parts)\n",
    "\n",
    "5. **Augmentation**\n",
    "  - Prompt templating\n",
    "  - Answer grounding\n",
    "  - Context window optimization\n",
    "\n",
    "6. **Generation**\n",
    "  - Answers with citations\n",
    "  - Guard railing\n",
    "\n",
    "7. **System Design**\n",
    "  - Multimodal RAG system\n",
    "  - Agentic workflows\n",
    "  - Memory-based architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
