{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQB78FuUIWpM"
      },
      "outputs": [],
      "source": [
        "# Setup for Ollama agent\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq8oB6ezIilj"
      },
      "outputs": [],
      "source": [
        "pip install -q langchain-ollama langchain-community langchain-core requests duckduckgo-search ddgs langchain langchain-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCeTJQRRIuH5"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.tools import tool\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbj_Y6W2I8Br"
      },
      "outputs": [],
      "source": [
        "# Create a simple search tool to avoid network issues\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def simple_search_tool(query: str) -> str:\n",
        "    \"\"\"Search for information. This is a mock search tool.\"\"\"\n",
        "    return f\"Mock search results for: {query}. This would normally return web search results.\"\n",
        "\n",
        "# Use the simple search tool\n",
        "search_tool = simple_search_tool\n",
        "results = search_tool.invoke('top news in india today')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "tVMZEIr6JHNG",
        "outputId": "92c6331d-326b-4c3d-da33-4a82ca36da14"
      },
      "outputs": [],
      "source": [
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "4OtTbxmzJ0VU",
        "outputId": "a6660f27-80dc-4825-b8a1-db7c92a74e8f"
      },
      "outputs": [],
      "source": [
        "llm = ChatOllama(\n",
        "    model=\"llama3:latest\",  # Fixed: using colon instead of dot\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXANH2dBJ50x"
      },
      "outputs": [],
      "source": [
        "llm.invoke('hi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI1nh0vdJ9Vg"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_react_agent , AgentExecutor\n",
        "from langchain import hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDtIk2UBKK47"
      },
      "outputs": [],
      "source": [
        "#step 2 pull the eract prmpt from langchain hub\n",
        "prompt = hub.pull(\"hwchase17/react\")  #pulls the standard react agent prompt here react = reasoning + action , lot of ai agents are there , thenfollow some design patterns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teb3-N4TKWWg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54SXRKaMKYbQ"
      },
      "outputs": [],
      "source": [
        "#step 3 create the react agent manually with the pulled prompt\n",
        "agent = create_react_agent(\n",
        "    llm =llm,\n",
        "    tools= [search_tool],\n",
        "    prompt = prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP8x3xW4K3n0"
      },
      "outputs": [],
      "source": [
        "# step 4 wrap it with AgentExecutor : agent : it is the main guy, planning , problem breakdown, decide, AgentExecutor : It is the guy who obeys AgentExedutor and executes it.\n",
        "agent_executor = AgentExecutor(\n",
        "    agent =agent,\n",
        "    tools = [search_tool],\n",
        "    verbose = True #whatever agent is thinking will be visible to us\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iH2acy2LILE"
      },
      "outputs": [],
      "source": [
        "# step Invoke :\n",
        "\n",
        "response = agent_executor.invoke({'input':'3 ways to reach goa from delhi'})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymPodWyIMNVj"
      },
      "outputs": [],
      "source": [
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtLIGBooMKCy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
